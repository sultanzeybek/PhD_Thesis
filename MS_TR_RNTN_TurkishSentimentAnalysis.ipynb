{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MS_TR_RNTN_TurkishSentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQiOKlk03GgY"
      },
      "source": [
        "# Sentiment Analisys with Recursive Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vctT_8EWSEOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e5962c-7470-48f7-defc-a0f280f79fc2"
      },
      "source": [
        "!curl https://colab.chainer.org/install | sh -"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1580  100  1580    0     0   9132      0 --:--:-- --:--:-- --:--:--  9080\r100  1580  100  1580    0     0   9132      0 --:--:-- --:--:-- --:--:--  9080\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |████████████████████████████████| 369.7MB 46kB/s \n",
            "\u001b[?25h+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH8mST0B5IK2"
      },
      "source": [
        "Let's import the necessary modules, then check the version of Chainer, NumPy, CuPy, Cuda and other execution environments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v00bch6E5Gf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4d3021-9d44-4545-e06d-429cd5664bd4"
      },
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "import chainer\n",
        "from chainer import cuda\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer.training import extensions\n",
        "from chainer import reporter\n",
        "\n",
        "\n",
        "chainer.print_runtime_info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/chainer/backends/cuda.py:147: UserWarning: cuDNN is not enabled.\n",
            "Please reinstall CuPy after you install cudnn\n",
            "(see https://docs-cupy.chainer.org/en/stable/install.html#install-cudnn).\n",
            "  'cuDNN is not enabled.\\n'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Platform: Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Chainer: 7.4.0\n",
            "ChainerX: Not Available\n",
            "NumPy: 1.18.5\n",
            "CuPy:\n",
            "  OS                           : Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "  CuPy Version                 : 8.2.0\n",
            "  NumPy Version                : 1.18.5\n",
            "  SciPy Version                : 1.4.1\n",
            "  Cython Build Version         : 0.29.21\n",
            "  CUDA Root                    : /usr/local/cuda\n",
            "  CUDA Build Version           : 10000\n",
            "  CUDA Driver Version          : 10010\n",
            "  CUDA Runtime Version         : 10000\n",
            "  cuBLAS Version               : 10000\n",
            "  cuFFT Version                : 10000\n",
            "  cuRAND Version               : 10000\n",
            "  cuSOLVER Version             : (10, 0, 0)\n",
            "  cuSPARSE Version             : 10000\n",
            "  NVRTC Version                : (10, 0)\n",
            "  Thrust Version               : 100903\n",
            "  CUB Build Version            : 100800\n",
            "  cuDNN Build Version          : 7605\n",
            "  cuDNN Version                : 7605\n",
            "  NCCL Build Version           : 2604\n",
            "  NCCL Runtime Version         : 2604\n",
            "  cuTENSOR Version             : None\n",
            "  Device 0 Name                : Tesla T4\n",
            "  Device 0 Compute Capability  : 75\n",
            "iDeep: 2.0.0.post3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjBUS6Cr8Sye"
      },
      "source": [
        "### 2. Setting parameters\n",
        "Here we set the parameters for training.\n",
        "* `` n_epoch``: Epoch number. How many times we pass through the whole training data.\n",
        "* `` n_units``: Number of units. How many hidden state vectors each Recursive Neural Network node has.\n",
        "* `` batchsize``: Batch size. How many train data we will input as a block when updating parameters.\n",
        "* `` n_label``: Number of labels. Number of classes to be identified. Since there are 5 labels this time, `` 5``.\n",
        "* `` epoch_per_eval``: How often to perform validation.\n",
        "* `` is_test``: If `` True``, we use a small dataset.\n",
        "* `` gpu_id``: GPU ID. The ID of the GPU to use. For Colaboratory it is good to use `` 0``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ha6-ramShVF"
      },
      "source": [
        "# parameters\n",
        "n_epoch = 25  # number of epochs\n",
        "n_units = 30  # number of units per layer\n",
        "batchsize = 1  # minibatch size\n",
        "n_label = 2  # number of labels\n",
        "epoch_per_eval = 2 # number of epochs per evaluation\n",
        "is_test = False\n",
        "gpu_id = 1\n",
        "\n",
        "if is_test:\n",
        "    max_size = 10\n",
        "else:\n",
        "    max_size = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3PnMSM78akB"
      },
      "source": [
        "### 3. Preparing the iterator\n",
        "\n",
        "Let's read the dataset used for training, validation, test and create an Iterator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ermPnCx061Hq"
      },
      "source": [
        "First, we convert each sample represented by ``str`` type to a tree structure data represented by a ``dictionary`` type.\n",
        "\n",
        "We will tokenize the string with `` read_corpus`` implemented by the parser `` SexpParser``. After that, we convert each tokenized sample to a tree structure data  by `` convert_tree``. By doing like this, it is possible to express a label as ``int``, a node as a two-element ``tuple``, and a tree structure as a ``dictionary``, making it a more manageable data structure than the original string.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqEzpAzMeMVo"
      },
      "source": [
        "# data.py\n",
        "import codecs\n",
        "import re\n",
        "\n",
        "\n",
        "class SexpParser(object):\n",
        "\n",
        "    def __init__(self, line):\n",
        "        self.tokens = re.findall(r'\\(|\\)|[^\\(\\) ]+', line)\n",
        "        self.pos = 0\n",
        "        \n",
        "\n",
        "    def parse(self):\n",
        "        assert self.pos < len(self.tokens)\n",
        "        token = self.tokens[self.pos]\n",
        "        assert token != ')'\n",
        "        self.pos += 1\n",
        "        \n",
        "        \n",
        "        if token == '(':\n",
        "            children = []\n",
        "            while True:\n",
        "                assert self.pos < len(self.tokens)\n",
        "                if self.tokens[self.pos] == ')':\n",
        "                    self.pos += 1\n",
        "                    break\n",
        "                else:\n",
        "                    children.append(self.parse())            \n",
        "            return children\n",
        "        else:\n",
        "            return token\n",
        "\n",
        "\n",
        "def read_corpus(path, max_size):\n",
        "    with codecs.open(path, encoding='utf-8') as f:\n",
        "        trees = []\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            tree = SexpParser(line).parse()\n",
        "            trees.append(tree)\n",
        "            if max_size and len(trees) >= max_size:\n",
        "                break\n",
        "    \n",
        "    return trees\n",
        "\n",
        "def convert_tree(vocab, exp):\n",
        "    assert isinstance(exp, list) and (len(exp) == 2 or len(exp) == 3)\n",
        "    if len(exp) == 2:\n",
        "        label, leaf = exp\n",
        "        if leaf not in vocab:\n",
        "            vocab[leaf] = len(vocab)\n",
        "        return {'label': int(label), 'node': vocab[leaf]}\n",
        "    elif len(exp) == 3:\n",
        "        label, left, right = exp\n",
        "       # f.write('new node'+\"\\n\")\n",
        "        node = (convert_tree(vocab, left), convert_tree(vocab, right))\n",
        "       # print(exp)\n",
        "       # f.write('new node'+\"\\n\")\n",
        "        return {'label': int(label), 'node': node}\n",
        "\n",
        "def convert_tree2(vocab, exp, f):\n",
        "    assert isinstance(exp, list) and (len(exp) == 2 or len(exp) == 3)\n",
        "    if len(exp) == 2:\n",
        "        label, leaf = exp\n",
        "        if leaf not in vocab:\n",
        "            vocab[leaf] = len(vocab)\n",
        "        return {'label': int(label), 'node': vocab[leaf]}\n",
        "    elif len(exp) == 3:\n",
        "        label, left, right = exp\n",
        "       # f.write('new node'+\"\\n\")\n",
        "        node = (convert_tree(vocab, left, f), convert_tree(vocab, right, f))\n",
        "       # print(exp)\n",
        "        f.write('new node'+\"\\n\")\n",
        "        return {'label': int(label), 'node': node}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrP2AfaqXmpm"
      },
      "source": [
        "Let's use `` read_corpus () `` and `` convert_tree () `` to create an iterator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42l-fDBfRijd"
      },
      "source": [
        "\n",
        "vocab = {}\n",
        "\n",
        "train_data = [convert_tree(vocab, tree)\n",
        "                        for tree in read_corpus('/content/train.txt', max_size)]\n",
        "train_iter = chainer.iterators.SerialIterator(train_data, batchsize)\n",
        "\n",
        "validation_data = [convert_tree(vocab, tree)\n",
        "                                 for tree in read_corpus('/content/dev.txt', max_size)]\n",
        "validation_iter = chainer.iterators.SerialIterator(validation_data, batchsize,\n",
        "                                                                                   repeat=False, shuffle=False)\n",
        "\n",
        "test_data = [convert_tree(vocab, tree)\n",
        "                        for tree in read_corpus('/content/test.txt', max_size)]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE3MSUrj92Tn"
      },
      "source": [
        "Let's try to display the first element of `` test_data``. It is represented by the following tree structure, `` lable`` expresses the score of that `` node``, and the numerical value of the leaf `` node`` corresponds to the word id in the dictionary `` vocab``."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVUZPtjo8ycv"
      },
      "source": [
        "\n",
        "### 4. Preparing the model\n",
        "\n",
        "Let's define the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU55nEkoE_Kc"
      },
      "source": [
        "We traverse each node of the tree structure data by `` traverse`` and calculate the loss `` loss`` of the whole tree. The implementation of `` traverse`` is a recursive call, which will traverse child nodes in turn. (It is a common implementation when treating tree structure data!)\n",
        "\n",
        "First, we calculate the hidden state vector `` v``. In the case of a leaf node, we obtain a hidden state vector stored in `` embed`` by `` model.leaf(word) `` from word id`` word``. In the case of an intermediate node, the hidden vector is calculated with the hidden state vector `` left`` and `` right`` of the child nodes by `` v = model.node(left, right)``.\n",
        "\n",
        "`` loss += F.softmax_cross_entropy(y, t) `` adds the loss of the current node to the loss of the child node, then returns loss to the parent node by ``return loss, v``.\n",
        "\n",
        "After the line `` loss += F.softmax_cross_entropy(y, t)``, there are some lines for logging accuracy and etc. But it is not necessary for the model definition itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGICf_k0hzW8"
      },
      "source": [
        "class RecursiveNet(chainer.Chain):\n",
        "    \n",
        "    def traverse(self, node, evaluate=None, root=True):\n",
        "        if isinstance(node['node'], int):\n",
        "            # leaf node\n",
        "            word = self.xp.array([node['node']], np.int32)\n",
        "            loss = 0\n",
        "            v = model.leaf(word)\n",
        "        else:\n",
        "            # internal node\n",
        "            left_node, right_node = node['node']\n",
        "            left_loss, left = self.traverse(left_node, evaluate=evaluate, root=False)\n",
        "            right_loss, right = self.traverse(right_node, evaluate=evaluate, root=False)\n",
        "            v = model.node(left, right)\n",
        "            loss = left_loss + right_loss\n",
        "\n",
        "        y = model.label(v)\n",
        "\n",
        "        label = self.xp.array([node['label']], np.int32)\n",
        "        t = chainer.Variable(label)\n",
        "        loss += F.softmax_cross_entropy(y, t)\n",
        "\n",
        "        predict = cuda.to_cpu(y.data.argmax(1))\n",
        "        if predict[0] == node['label']:\n",
        "            evaluate['correct_node'] += 1\n",
        "        evaluate['total_node'] += 1\n",
        "  \n",
        "        if root:\n",
        "            if predict[0] == node['label']:\n",
        "                evaluate['correct_root'] += 1\n",
        "            evaluate['total_root'] += 1\n",
        "\n",
        "        return loss, v\n",
        "\n",
        "    def __init__(self, n_vocab, n_units):\n",
        "        super(RecursiveNet, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.embed = L.EmbedID(n_vocab, n_units)\n",
        "            self.l = L.Linear(n_units * 2, n_units)\n",
        "            self.w = L.Linear(n_units, n_label)\n",
        "\n",
        "    def leaf(self, x):\n",
        "        return self.embed(x)\n",
        "\n",
        "    def node(self, left, right):\n",
        "        return F.tanh(self.l(F.concat((left, right))))\n",
        "\n",
        "    def label(self, v):\n",
        "        return self.w(v)\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        accum_loss = 0.0\n",
        "        result = collections.defaultdict(lambda: 0)\n",
        "        for tree in x:\n",
        "            loss, _ = self.traverse(tree, evaluate=result)\n",
        "            accum_loss += loss\n",
        "        \n",
        "        reporter.report({'loss': accum_loss}, self)\n",
        "        reporter.report({'total': result['total_node']}, self)\n",
        "        reporter.report({'correct': result['correct_node']}, self)\n",
        "        return accum_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYsIEJUI_Km4"
      },
      "source": [
        "One attention to the implementation of `` __call__``.\n",
        "\n",
        "`` x`` passed to `` __call__`` is mini-batched input data and contains samples `` s_n`` like `` [s_1, s_2, ..., s_N] ``.\n",
        "\n",
        "In a network such as Convolutional Network used for image recognition, it is possible to perform parallel calculation collectively for mini batch `` x``. However, in the case of a tree-structured network like this one, it is difficult to compute parallel because of the following reasons.\n",
        "\n",
        "* Data length varies depending on samples.\n",
        "* The order of calculation for each sample is different.\n",
        "\n",
        "So, the implementation is to calculate each sample and finally summarize the results.\n",
        " \n",
        "Note: Actually, you can perform parallel calculation of mini batch in Recursive Neural Network by using stack. Since it is published in the latter part of notebook as (Advanced), please refer to it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnBhdpO8igK9"
      },
      "source": [
        "model = RecursiveNet(len(vocab), n_units)\n",
        "\n",
        "if gpu_id >= 0:\n",
        "   model.to_gpu()\n",
        "\n",
        "# Setup optimizer\n",
        "optimizer = chainer.optimizers.AdaGrad(lr=0.01)\n",
        "optimizer.setup(model)\n",
        "optimizer.add_hook(chainer.optimizer_hooks.WeightDecay(0.0001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTq_sX298-ZR"
      },
      "source": [
        "### 5. Preparation and training of Updater · Trainer\n",
        "\n",
        "As usual, we define an updater and a trainer to train the model.\n",
        "This time, I do not use `` L.Classifier`` and calculate the accuracy `` accuracy`` by myself. You can easily implement it using `` extensions.MicroAverage``. For details, please refer to [chainer.training.extensions.MicroAverage](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.MicroAverage.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXAIZSy9cQdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73dace2f-5c44-4fc0-bba0-459d842a6bdf"
      },
      "source": [
        "def _convert(batch, device):\n",
        "  return batch\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "updater = chainer.training.StandardUpdater(\n",
        "    train_iter, optimizer, device=gpu_id, converter=_convert)\n",
        "\n",
        "trainer = chainer.training.Trainer(updater, (n_epoch, 'epoch'))\n",
        "trainer.extend(\n",
        "        extensions.Evaluator(validation_iter, model, device=gpu_id, converter=_convert),\n",
        "        trigger=(epoch_per_eval, 'epoch'))\n",
        "trainer.extend(extensions.LogReport())\n",
        "\n",
        "trainer.extend(extensions.MicroAverage(\n",
        "        'main/correct', 'main/total', 'main/accuracy'))\n",
        "trainer.extend(extensions.MicroAverage(\n",
        "        'validation/main/correct', 'validation/main/total',\n",
        "        'validation/main/accuracy'))\n",
        "\n",
        "trainer.extend(extensions.PrintReport(\n",
        "        ['epoch', 'main/loss', 'validation/main/loss', \n",
        "          'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
        "\n",
        "trainer.extend(\n",
        "    extensions.PlotReport(['main/loss', 'validation/main/loss'],\n",
        "                          'epoch', filename='loss.png'))\n",
        "\n",
        "trainer.extend(\n",
        "    extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'],\n",
        "                          'epoch', filename='accuracy.png'))\n",
        "\n",
        "\n",
        "trainer.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/chainer/training/updaters/standard_updater.py:142: FutureWarning: Transfer between @cupy devices was detected and skipped. StandardUpdater normally transfers the model to the specified device, but except for between @cupy devices. That is, if a part of the model is on @cupy:n device and the specified device is @cupy:m device, that part of the model will be left in @cupy:n device. This behavior is planned to be changed in near future. After that, the model will be transferred to the specified device regardless of device combination. If you want to keep the model device but only want to transfer the input data to a given device, specify the 'input_device' argument instead and leave the 'device' argument unspecified.\n",
            "\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
            "\u001b[J1           18.9048                           0.705352                                 2420.82       \n",
            "\u001b[J2           16.5162     15.5985               0.748959       0.76421                   4944.03       \n",
            "\u001b[J3           15.1737                           0.769564                                 7160.79       \n",
            "\u001b[J4           14.2003     13.7116               0.78493        0.793349                  9635.98       \n",
            "\u001b[J5           13.4844                           0.796335                                 11937.9       \n",
            "\u001b[J6           12.9102     12.6559               0.805611       0.810277                  14285         \n",
            "\u001b[J7           12.4365                           0.81389                                  16517.4       \n",
            "\u001b[J8           12.0371     11.8765               0.82162        0.826217                  18946.4       \n",
            "\u001b[J9           11.6926                           0.82869                                  21234.8       \n",
            "\u001b[J10          11.3957     11.3091               0.834915       0.838657                  23731.2       \n",
            "\u001b[J11          11.1368                           0.840649                                 26100.5       \n",
            "\u001b[J12          10.909      10.8612               0.846166       0.849158                  28637.3       \n",
            "\u001b[J13          10.7041                           0.850705                                 31052.9       \n",
            "\u001b[J14          10.5147     10.4746               0.855459       0.858263                  33500.8       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7wiomoIvjc1"
      },
      "source": [
        "### 6. Checking the performance with test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4g1JkNWv86t"
      },
      "source": [
        "def evaluate(model, test_trees):\n",
        "    result = collections.defaultdict(lambda: 0)\n",
        "    with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
        "        for tree in test_trees:\n",
        "            model.traverse(tree, evaluate=result)\n",
        "    acc_node = 100.0 * result['correct_node'] / result['total_node']\n",
        "    acc_root = 100.0 * result['correct_root'] / result['total_root']\n",
        "    print(' Total Node accuracy: {0:.2f} %% ({1:,d}/{2:,d})'.format(\n",
        "        acc_node, result['correct_node'], result['total_node']))\n",
        "    print(' Sentence Level (Root) accuracy: {0:.2f} %% ({1:,d}/{2:,d})'.format(\n",
        "        acc_root, result['correct_root'], result['total_root']))\n",
        "            \n",
        "print('Test evaluation')\n",
        "evaluate(model, test_data)\n",
        "evaluate(model, validation_data)\n",
        "evaluate(model, train_data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}